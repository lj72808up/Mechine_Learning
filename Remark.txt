1. 回归线性方程： regression
2. 用一条线性方程拟合存在的样本点： y = mx + b
3. 最大程度的降低误差的平方和，最佳回归是最小化误差平方和的回归
   为求得所有点最小误差平方和时的ｍ和ｂ，出现了很多算法，sklearn中使用OLS（ordinary least squares）
   而使用误差绝对值的平方和，而不是误差的绝对值来计算，是因为，平方后会取得更清晰的结果。比如：一条直线与上下两点的误差绝对值为３和６，零一条直线为４和５,　这种绝对值和一样，但是
   绝对值的平方和不一样。
4. 误差平方和作为指标，并不能最贴切的描述直线的拟合程度，因为少样本数量产生的拟合直线势必使得误差平方和小
5. r平方指标